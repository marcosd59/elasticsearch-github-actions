import uuid
import pandas as pd
from elasticsearch import Elasticsearch
from elasticsearch.helpers import parallel_bulk
import time

# ‚úÖ Par√°metros de conexi√≥n
ELASTICSEARCH_URL = 'http://localhost:9200'
INDEX_NAME = 'stock_data'

# ‚úÖ Leer CSV
print("üì• Reading CSV file...")
df = pd.read_csv('stock_data.csv')

# ‚úÖ Renombrar columnas (opcional)
df.columns = ['Fecha', 'Precio Cierre',
              'M√°ximo', 'M√≠nimo', 'Apertura', 'Volumen']

# ‚úÖ Limpieza de datos
df['Fecha'] = pd.to_datetime(df['Fecha'], errors='coerce')
df['Precio Cierre'] = pd.to_numeric(
    df['Precio Cierre'], errors='coerce').fillna(0)
df['M√°ximo'] = pd.to_numeric(df['M√°ximo'], errors='coerce').fillna(0)
df['M√≠nimo'] = pd.to_numeric(df['M√≠nimo'], errors='coerce').fillna(0)
df['Apertura'] = pd.to_numeric(df['Apertura'], errors='coerce').fillna(0)
df['Volumen'] = pd.to_numeric(
    df['Volumen'], errors='coerce').fillna(0).astype(int)

# ‚úÖ Intentar conectar a Elasticsearch con reintentos
RETRIES = 5
connected = False

for i in range(RETRIES):
    try:
        print(
            f"üöÄ Attempting to connect to Elasticsearch (try {i + 1}/{RETRIES})...")
        es = Elasticsearch(ELASTICSEARCH_URL)
        if es.ping():
            connected = True
            print("‚úÖ Connected to Elasticsearch!")
            break
    except Exception as e:
        print(f"‚ùå Connection failed: {e}")
        time.sleep(5)

if not connected:
    raise ConnectionError(
        "‚ùå Could not connect to Elasticsearch after multiple attempts")

# ‚úÖ Crear √≠ndice si no existe
if not es.indices.exists(index=INDEX_NAME):
    print(f"üì¢ Creating index '{INDEX_NAME}'...")
    mapping = {
        "mappings": {
            "properties": {
                "Fecha": {"type": "date"},
                "Precio Cierre": {"type": "float"},
                "M√°ximo": {"type": "float"},
                "M√≠nimo": {"type": "float"},
                "Apertura": {"type": "float"},
                "Volumen": {"type": "integer"}
            }
        }
    }
    es.indices.create(index=INDEX_NAME, body=mapping)
    print(f"‚úÖ Index '{INDEX_NAME}' created successfully")

# ‚úÖ Generar documentos para Elasticsearch


def generate_docs(df):
    for _, row in df.iterrows():
        yield {
            "_index": INDEX_NAME,
            # Generar un ID √∫nico para cada documento
            "_id": str(uuid.uuid4()),
            "_source": row.to_dict()
        }


# ‚úÖ Insertar datos en Elasticsearch en lotes
print("üöÄ Inserting data into Elasticsearch...")
for success, info in parallel_bulk(es, generate_docs(df), chunk_size=50):
    if not success:
        print(f"‚ùå Failed to insert document: {info}")

print(f"‚úÖ Data loaded successfully into '{INDEX_NAME}'!")
